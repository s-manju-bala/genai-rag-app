# **Retrieval-Augmented Generation (RAG) system using LangChain + OpenAI + ChromaDB for context-aware Q&A.**

## ğŸ“Œ **Overview**
This project implements a **Retrieval-Augmented Generation (RAG)** system using **LangChain, OpenAI GPT models, and ChromaDB**.  
It ingests unstructured data (**documents, websites, speeches**), stores them as **embeddings in a vector database**, and generates **context-aware factual answers** to user queries.  

This app demonstrates how **Generative AI + Retrieval Pipelines** can reduce hallucinations and provide **reliable outputs**.  

---

## ğŸš€ **Features**
- ğŸ“„ **Document Ingestion** â†’ Load text files, speeches, or web pages  
- âœ‚ï¸ **Text Chunking** â†’ Split documents into semantically meaningful chunks  
- ğŸ” **Vector Store with ChromaDB** â†’ Store embeddings for efficient semantic search  
- ğŸ’¡ **Contextual Retrieval** â†’ Fetch most relevant chunks for each query  
- ğŸ¤– **Answer Generation with GPT** â†’ Generate factual, context-rich answers  
- ğŸ“Š **LangSmith Tracing** â†’ Monitor and debug RAG pipeline performance  

---

## ğŸ›  **Tech Stack**
- **Python** ğŸ  
- **LangChain**  
- **OpenAI GPT Models**  
- **ChromaDB** ğŸ—„ï¸  
- **BeautifulSoup** (for HTML parsing)  
- **tiktoken** (token management)  
- **LangSmith** (monitoring & tracing)  

---

## ğŸ“‚ **Project Structure**

genai-rag-app/

â”‚â”€â”€ app.py

â”‚â”€â”€ local_llama.py

â”‚â”€â”€ requirements.txt

â”‚â”€â”€ .env

â”‚â”€â”€ /rag

â”‚    â”œâ”€â”€ attention.pdf

â”‚    â”œâ”€â”€ simplerag.ipynb

â”‚    â””â”€â”€ speech.txt

---

### 2ï¸âƒ£ **Install dependencies**
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Set up environment variables**

Create a .env file with:

OPENAI_API_KEY=your_api_key_here

LANGSMITH_API_KEY=your_langsmith_key_here   # optional

---

### ğŸ“Š **Example Query**
"Explain the Attention mechanism in Transformers."

### **Output (sample):**
âœ¨ A context-rich explanation retrieved from the ingested â€œAttention Is All You Needâ€ paper, citing relevant sections to reduce hallucinations.

---

### ğŸ”® **Future Roadmap**

ğŸš€ Wrap RAG pipeline into a FastAPI backend

ğŸ“‘ Support PDF, Word, and multi-file ingestion

â˜ï¸ Deploy on Azure / AWS / GCP

ğŸ³ Add Docker + CI/CD for production readiness

ğŸ¤ Extend with multi-agent workflows (LangGraph, Autogen)

---

### ğŸ‘©â€ğŸ’» **Author**

Manju Bala S

AI Engineer & Data Scientist

Specializing in Generative AI, RAG Systems, SQL Optimization with LLMs, and AI Agents

---


